# HOW TO CUSTOMIZE YOUR OWN MODEL
# ----------------------------
# This configuration file allows you to define machine learning models with their hyperparameters.
# To add a new model, follow this structure:
#
# model_key:  # Short name for your model (e.g., 'my_classifier')
#   IMPORTS:
#     module: package.submodule  # Python module where the model class is located
#     class: ClassName  # Name of the model class to import
#   PARAM_SPACE:  # Parameters to tune during optimization
#     parameter_name:
#       type: categorical|float|integer  # Parameter type
#       values: [val1, val2] or {min: min_val, max: max_val, step: step_val, log: bool}
#   STATIC_PARAMS:  # Fixed parameters that won't be tuned
#     parameter_name: value
#   SHAP_EXPLAINER_TYPE: linear|kernel|tree|permutation  # Type of SHAP explainer to use
#   SAVE_TYPE: joblib|xgboost|lightgbm|catboost  # Method used to save the model
#
# PARAMETER TYPES:
# - categorical: discrete set of choices (list of values)
# - float: continuous numerical value (min/max range with optional step)
#   - log: true makes the sampling logarithmic
# - integer: whole numbers (min/max range with optional step)
#
# SHAP EXPLAINER TYPES:
# - linear: for linear models (faster for LinearRegression, LogisticRegression)
# - kernel: model-agnostic explainer (can be used with any model, but slower)
# - tree: optimized for tree-based models (RandomForest, XGBoost, etc.)
# - permutation: feature permutation-based approach for black-box models
#
# SAVE TYPES:
# - joblib: default for scikit-learn models
# - xgboost: for XGBoost models (saves as .json)
# - lightgbm: for LightGBM models (saves as .txt)
# - catboost: for CatBoost models (saves as .cbm)



# Classifiers
lc:  # LogisticRegression
  IMPORTS:
    module: sklearn.linear_model
    class: LogisticRegression
  PARAM_SPACE:
    solver:
      type: categorical
      values: ["lbfgs", "saga"]
    penalty:
      type: categorical
      values: ["l2", null]
    C:
      type: float
      values: {min: 0.01, max: 10.0, log: true}
    max_iter:
      type: integer
      values: {min: 100, max: 1000, step: 100}
  STATIC_PARAMS:
    class_weight: balanced
    tol: 1.0e-4
    fit_intercept: true
    n_jobs: -1
    verbose: 0
    warm_start: false
  SHAP_EXPLAINER_TYPE: linear
  SAVE_TYPE: joblib

svc:  # SVC
  IMPORTS:
    module: sklearn.svm
    class: SVC
  PARAM_SPACE:
    kernel:
      type: categorical
      values: ["linear", "rbf", "poly", "sigmoid"]
    C:
      type: float
      values: {min: 0.1, max: 200, log: true}
    degree:
      type: integer
      values: {min: 2, max: 5}
  STATIC_PARAMS:
    class_weight: balanced
    probability: true
    verbose: 0
  SHAP_EXPLAINER_TYPE: kernel
  SAVE_TYPE: joblib

knc:  # KNeighborsClassifier
  IMPORTS:
    module: sklearn.neighbors
    class: KNeighborsClassifier
  PARAM_SPACE:
    n_neighbors:
      type: integer
      values: {min: 1, max: 50, step: 1}
    weights:
      type: categorical
      values: ["uniform", "distance"]
    algorithm:
      type: categorical
      values: ["auto", "ball_tree", "kd_tree", "brute"]
    leaf_size:
      type: integer
      values: {min: 10, max: 100, step: 10}
    p:
      type: integer
      values: {min: 1, max: 2}
  STATIC_PARAMS:
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: permutation
  SAVE_TYPE: joblib

mlpc:  # MLPClassifier
  IMPORTS:
    module: sklearn.neural_network
    class: MLPClassifier
  PARAM_SPACE:
    activation:
      type: categorical
      values: ["relu", "tanh", "logistic"]
    alpha:
      type: float
      values: {min: 0.0001, max: 0.1, log: true}
    learning_rate:
      type: categorical
      values: ["constant", "adaptive"]
    learning_rate_init:
      type: float
      values: {min: 0.0001, max: 0.1, log: true}
    max_iter:
      type: integer
      values: {min: 100, max: 3000, step: 100}
  STATIC_PARAMS:
    hidden_layer_sizes: [300, 300, 300]
    solver: adam
    batch_size: auto
    early_stopping: true
    n_iter_no_change: 10
    verbose: 0
  SHAP_EXPLAINER_TYPE: kernel
  SAVE_TYPE: joblib

dtc:  # DecisionTreeClassifier
  IMPORTS:
    module: sklearn.tree
    class: DecisionTreeClassifier
  PARAM_SPACE:
    criterion:
      type: categorical
      values: ["gini", "entropy", "log_loss"]
    max_depth:
      type: integer
      values: {min: 2, max: 20}
    min_samples_split:
      type: integer
      values: {min: 2, max: 20}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 20}
    max_features:
      type: float
      values: {min: 0.2, max: 1.0}
    class_weight:
      type: categorical
      values: ["balanced", null]
  STATIC_PARAMS: {}
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

rfc:  # RandomForestClassifier
  IMPORTS:
    module: sklearn.ensemble
    class: RandomForestClassifier
  PARAM_SPACE:
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    criterion:
      type: categorical
      values: ["gini", "entropy", "log_loss"]
    max_depth:
      type: integer
      values: {min: 1, max: 15}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 5, step: 1}
    min_samples_split:
      type: integer
      values: {min: 2, max: 10, step: 1}
    max_features:
      type: float
      values: {min: 0.1, max: 1.0, step: 0.1}
    bootstrap:
      type: categorical
      values: [true, false]
    class_weight:
      type: categorical
      values: ["balanced", "balanced_subsample", null]
  STATIC_PARAMS:
    verbose: 0
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

gbdtc:  # GradientBoostingClassifier
  IMPORTS:
    module: sklearn.ensemble
    class: GradientBoostingClassifier
  PARAM_SPACE:
    learning_rate:
      type: float
      values: {min: 0.001, max: 0.3, log: true}
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 50}
    subsample:
      type: float
      values: {min: 0.5, max: 1.0, step: 0.1}
    criterion:
      type: categorical
      values: ["friedman_mse", "squared_error"]
    min_samples_split:
      type: integer
      values: {min: 2, max: 10, step: 1}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 5, step: 1}
    max_depth:
      type: integer
      values: {min: 3, max: 8}
    max_features:
      type: float
      values: {min: 0.2, max: 1.0, step: 0.1}
  STATIC_PARAMS:
    verbose: 0
    validation_fraction: 0.1
    n_iter_no_change: 10
    tol: 1.0e-4
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

adac:  # AdaBoostClassifier
  IMPORTS:
    module: sklearn.ensemble
    class: AdaBoostClassifier
  PARAM_SPACE:
    n_estimators:
      type: integer
      values: {min: 50, max: 3000, step: 50}
    learning_rate:
      type: float
      values: {min: 0.01, max: 1.0, log: true}
  STATIC_PARAMS:
    algorithm: SAMME
  SHAP_EXPLAINER_TYPE: permutation
  SAVE_TYPE: joblib

xgbc:  # XGBClassifier
  IMPORTS:
    module: xgboost
    class: XGBClassifier
  PARAM_SPACE:
    max_depth:
      type: integer
      values: {min: 3, max: 10}
    learning_rate:
      type: float
      values: {min: 0.01, max: 0.3, log: true}
    n_estimators:
      type: integer
      values: {min: 50, max: 3000, step: 50}
    subsample:
      type: float
      values: {min: 0.5, max: 1.0, step: 0.1}
    colsample_bytree:
      type: float
      values: {min: 0.5, max: 1.0, step: 0.1}
    colsample_bylevel:
      type: float
      values: {min: 0.5, max: 1.0, step: 0.1}
    min_child_weight:
      type: integer
      values: {min: 1, max: 10}
    gamma:
      type: float
      values: {min: 0, max: 1, step: 0.1}
    reg_alpha:
      type: float
      values: {min: 0.001, max: 10.0, log: true}
    reg_lambda:
      type: float
      values: {min: 0.001, max: 10.0, log: true}
    tree_method:
      type: categorical
      values: ["auto", "exact", "approx", "hist"]
  STATIC_PARAMS:
    booster: gbtree
    enable_categorical: false
    verbosity: 0
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: json

lgbc:  # LGBMClassifier
  IMPORTS:
    module: lightgbm
    class: LGBMClassifier
  PARAM_SPACE:
    num_leaves:
      type: integer
      values: {min: 20, max: 150}
    max_depth:
      type: integer
      values: {min: -1, max: 15}
    learning_rate:
      type: float
      values: {min: 0.01, max: 0.3, log: true}
    n_estimators:
      type: integer
      values: {min: 50, max: 3000, step: 50}
    min_child_samples:
      type: integer
      values: {min: 5, max: 100}
    subsample:
      type: float
      values: {min: 0.5, max: 1.0, step: 0.1}
    subsample_freq:
      type: integer
      values: {min: 0, max: 10}
    colsample_bytree:
      type: float
      values: {min: 0.5, max: 1.0}
    reg_alpha:
      type: float
      values: {min: 0.001, max: 10.0, log: true}
    reg_lambda:
      type: float
      values: {min: 0.001, max: 10.0, log: true}
    min_split_gain:
      type: float
      values: {min: 0, max: 0.5}
  STATIC_PARAMS:
    boosting_type: gbdt
    verbose: -1
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: txt

catc:  # CatBoostClassifier
  IMPORTS:
    module: catboost
    class: CatBoostClassifier
  PARAM_SPACE:
    iterations:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    learning_rate:
      type: float
      values: {min: 0.01, max: 0.3, log: true}
    depth:
      type: integer
      values: {min: 4, max: 10}
    l2_leaf_reg:
      type: float
      values: {min: 1.0, max: 10.0, log: true}
    bagging_temperature:
      type: float
      values: {min: 0.0, max: 1.0}
    random_strength:
      type: float
      values: {min: 0.0, max: 1.0}
    border_count:
      type: integer
      values: {min: 32, max: 255}
    grow_policy:
      type: categorical
      values: ["SymmetricTree", "Depthwise", "Lossguide"]
    min_data_in_leaf:
      type: integer
      values: {min: 1, max: 50}
  STATIC_PARAMS:
    verbose: 0
    allow_writing_files: false
    train_dir: null
    thread_count: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: cbm



# Regressors
lr:  # LinearRegression
  IMPORTS:
    module: sklearn.linear_model
    class: LinearRegression
  PARAM_SPACE: {}
  STATIC_PARAMS: {}
  SHAP_EXPLAINER_TYPE: linear
  SAVE_TYPE: joblib

svr:  # SVR
  IMPORTS:
    module: sklearn.svm
    class: SVR
  PARAM_SPACE:
    kernel:
      type: categorical
      values: ["linear", "rbf", "poly", "sigmoid"]
    C:
      type: integer
      values: {min: 1, max: 200, step: 1}
    epsilon:
      type: float
      values: {min: 0.1, max: 10, step: 0.1}
  STATIC_PARAMS:
    verbose: 0
  SHAP_EXPLAINER_TYPE: kernel
  SAVE_TYPE: joblib

knr:  # KNeighborsRegressor
  IMPORTS:
    module: sklearn.neighbors
    class: KNeighborsRegressor
  PARAM_SPACE:
    n_neighbors:
      type: integer
      values: {min: 1, max: 10, step: 1}
    weights:
      type: categorical
      values: ["uniform", "distance"]
    algorithm:
      type: categorical
      values: ["auto", "ball_tree", "kd_tree", "brute"]
    leaf_size:
      type: integer
      values: {min: 1, max: 100, step: 1}
    p:
      type: integer
      values: {min: 1, max: 5, step: 1}
  STATIC_PARAMS:
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: permutation
  SAVE_TYPE: joblib

mlpr:  # MLPRegressor
  IMPORTS:
    module: sklearn.neural_network
    class: MLPRegressor
  PARAM_SPACE:
    alpha:
      type: float
      values: {min: 0.0001, max: 0.1, log: true}
    learning_rate_init:
      type: float
      values: {min: 0.0001, max: 0.1, log: true}
    max_iter:
      type: integer
      values: {min: 100, max: 3000, step: 100}
  STATIC_PARAMS:
    hidden_layer_sizes: [300, 300, 300]
    activation: relu
    solver: adam
    batch_size: auto
    verbose: 0
  SHAP_EXPLAINER_TYPE: kernel
  SAVE_TYPE: joblib

dtr:  # DecisionTreeRegressor
  IMPORTS:
    module: sklearn.tree
    class: DecisionTreeRegressor
  PARAM_SPACE:
    max_depth:
      type: integer
      values: {min: 2, max: 20}
    min_samples_split:
      type: integer
      values: {min: 2, max: 20}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 20}
    max_features:
      type: float
      values: {min: 0.2, max: 1.0}
  STATIC_PARAMS: {}
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

rfr:  # RandomForestRegressor
  IMPORTS:
    module: sklearn.ensemble
    class: RandomForestRegressor
  PARAM_SPACE:
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    max_depth:
      type: integer
      values: {min: 1, max: 15}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 5, step: 1}
    min_samples_split:
      type: integer
      values: {min: 2, max: 10, step: 1}
    max_features:
      type: float
      values: {min: 0.1, max: 1.0, step: 0.1}
  STATIC_PARAMS:
    verbose: 0
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

gbdtr:  # GradientBoostingRegressor
  IMPORTS:
    module: sklearn.ensemble
    class: GradientBoostingRegressor
  PARAM_SPACE:
    learning_rate:
      type: float
      values: {min: 1.0e-8, max: 1.0, log: true}
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    max_depth:
      type: integer
      values: {min: 1, max: 15}
    subsample:
      type: float
      values: {min: 0.2, max: 1.0, step: 0.1}
    min_samples_leaf:
      type: integer
      values: {min: 1, max: 5, step: 1}
    min_samples_split:
      type: integer
      values: {min: 2, max: 10, step: 1}
    max_features:
      type: float
      values: {min: 0.2, max: 1.0, step: 0.1}
  STATIC_PARAMS:
    verbose: 0
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: joblib

adar:  # AdaBoostRegressor
  IMPORTS:
    module: sklearn.ensemble
    class: AdaBoostRegressor
  PARAM_SPACE:
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    learning_rate:
      type: float
      values: {min: 0.01, max: 1.0, log: true}
    loss:
      type: categorical
      values: ["linear", "square", "exponential"]
  STATIC_PARAMS: {}
  SHAP_EXPLAINER_TYPE: permutation
  SAVE_TYPE: joblib

xgbr:  # XGBRegressor
  IMPORTS:
    module: xgboost
    class: XGBRegressor
  PARAM_SPACE:
    max_depth:
      type: integer
      values: {min: 1, max: 15}
    learning_rate:
      type: float
      values: {min: 1.0e-8, max: 1.0, log: true}
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    subsample:
      type: float
      values: {min: 0.2, max: 1.0, step: 0.1}
    colsample_bytree:
      type: float
      values: {min: 0.2, max: 1.0, step: 0.1}
    gamma:
      type: float
      values: {min: 0, max: 5, step: 0.1}
    min_child_weight:
      type: integer
      values: {min: 1, max: 10}
    reg_alpha:
      type: float
      values: {min: 0, max: 5}
    reg_lambda:
      type: float
      values: {min: 0.5, max: 5}
    tree_method:
      type: categorical
      values: ["hist", "approx"]
  STATIC_PARAMS:
    enable_categorical: false
    verbosity: 0
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: json

lgbr:  # LGBMRegressor
  IMPORTS:
    module: lightgbm
    class: LGBMRegressor
  PARAM_SPACE:
    max_depth:
      type: integer
      values: {min: 1, max: 15}
    learning_rate:
      type: float
      values: {min: 1.0e-8, max: 1.0, log: true}
    n_estimators:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    num_leaves:
      type: integer
      values: {min: 2, max: 256}
    colsample_bytree:
      type: float
      values: {min: 0.2, max: 1.0}
    subsample:
      type: float
      values: {min: 0.2, max: 1.0}
    subsample_freq:
      type: integer
      values: {min: 1, max: 7}
    reg_alpha:
      type: float
      values: {min: 1.0e-8, max: 10.0, log: true}
    reg_lambda:
      type: float
      values: {min: 1.0e-8, max: 10.0, log: true}
  STATIC_PARAMS:
    verbose: -1
    n_jobs: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: txt

catr:  # CatBoostRegressor
  IMPORTS:
    module: catboost
    class: CatBoostRegressor
  PARAM_SPACE:
    iterations:
      type: integer
      values: {min: 100, max: 3000, step: 100}
    learning_rate:
      type: float
      values: {min: 1.0e-5, max: 1.0, log: true}
    max_depth:
      type: integer
      values: {min: 3, max: 10}
    bagging_temperature:
      type: float
      values: {min: 0.0, max: 1.0}
    subsample:
      type: float
      values: {min: 0.05, max: 1.0}
    colsample_bylevel:
      type: float
      values: {min: 0.05, max: 1.0}
    min_data_in_leaf:
      type: integer
      values: {min: 1, max: 100}
    l2_leaf_reg:
      type: float
      values: {min: 1.0, max: 10.0, log: true}
    leaf_estimation_iterations:
      type: integer
      values: {min: 1, max: 10}
  STATIC_PARAMS:
    verbose: 0
    allow_writing_files: false
    train_dir: null
    thread_count: -1
  SHAP_EXPLAINER_TYPE: tree
  SAVE_TYPE: cbm