{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarviski/miniconda3/envs/mymodels/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mymodels.data_engineer import data_engineer\n",
    "from mymodels.pipeline import MyPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyPipeline(\n",
    "    results_dir = \"results/housing\",\n",
    "    random_state = 0,\n",
    "    show = False,\n",
    "    plot_format = \"jpg\",\n",
    "    plot_dpi = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 506\n",
      "\n",
      "Train X data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 354 entries, H-142 to H-173\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     342 non-null    float64\n",
      " 1   ZN       340 non-null    float64\n",
      " 2   INDUS    339 non-null    float64\n",
      " 3   CHAS     340 non-null    float64\n",
      " 4   NOX      354 non-null    float64\n",
      " 5   RM       354 non-null    float64\n",
      " 6   AGE      340 non-null    float64\n",
      " 7   DIS      354 non-null    float64\n",
      " 8   RAD      354 non-null    int64  \n",
      " 9   TAX      354 non-null    int64  \n",
      " 10  PTRATIO  354 non-null    float64\n",
      " 11  B        354 non-null    float64\n",
      " 12  LSTAT    337 non-null    float64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 38.7+ KB\n",
      "None\n",
      "\n",
      "Train X data head:\n",
      "           CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD  TAX  \\\n",
      "ID                                                                          \n",
      "H-142   1.62864   0.0  21.89   0.0  0.624  5.019  100.0  1.4394    4  437   \n",
      "H-273   0.11460  20.0   6.96   0.0  0.464  6.538   58.7  3.9175    3  223   \n",
      "H-136   0.55778   0.0  21.89   0.0  0.624  6.335   98.2  2.1107    4  437   \n",
      "H-299   0.06466  70.0   2.24   0.0  0.400  6.345   20.1  7.8278    5  358   \n",
      "H-123   0.09299   0.0  25.65   0.0  0.581  5.961   92.9  2.0869    2  188   \n",
      "H-23    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769    4  307   \n",
      "H-69    0.13554  12.5   6.07   0.0  0.409  5.594   36.8  6.4980    4  345   \n",
      "H-21    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979    4  307   \n",
      "H-438  15.17720   0.0  18.10   0.0  0.740  6.152  100.0  1.9142   24  666   \n",
      "H-15    0.63796   0.0   8.14   NaN  0.538  6.096   84.5  4.4619    4  307   \n",
      "\n",
      "       PTRATIO       B  LSTAT  \n",
      "ID                             \n",
      "H-142     21.2  396.90  34.41  \n",
      "H-273     18.6  394.96   7.73  \n",
      "H-136     21.2  394.67  16.96  \n",
      "H-299     14.8  368.24   4.97  \n",
      "H-123     19.1  378.09  17.93  \n",
      "H-23      21.0  396.90  18.72  \n",
      "H-69      18.9  396.90  13.09  \n",
      "H-21      21.0  376.57  21.02  \n",
      "H-438     20.2    9.32  26.45  \n",
      "H-15      21.0  380.02  10.26  \n",
      "\n",
      "Train y data info:\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 354 entries, H-142 to H-173\n",
      "Series name: MEDV\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "354 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 5.5+ KB\n",
      "None\n",
      "\n",
      "Train y data head:\n",
      "ID\n",
      "H-142    14.4\n",
      "H-273    24.4\n",
      "H-136    18.1\n",
      "H-299    22.5\n",
      "H-123    20.5\n",
      "H-23     15.2\n",
      "H-69     17.4\n",
      "H-21     13.6\n",
      "H-438     8.7\n",
      "H-15     18.2\n",
      "Name: MEDV, dtype: float64\n",
      "\n",
      "Totally features: 13\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/housing.csv\", encoding = \"utf-8\", \n",
    "                   na_values = np.nan, index_col = [\"ID\"])\n",
    "mymodel.load(\n",
    "    input_data = data,\n",
    "    y = \"MEDV\",\n",
    "    x_list = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \\\n",
    "              \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"],\n",
    "    test_ratio = 0.3,\n",
    "    inspect = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "Data diagnosis should be performed on TRAINING DATA ONLY.\n",
      "=========================================================\n",
      "\n",
      "==========================================\n",
      "DATA DESCRIPTION\n",
      "\n",
      "X_train shape: (354, 13)\n",
      "\n",
      "Y_train shape: (354,)\n",
      "==========================================\n",
      "==========================================\n",
      "MISSING VALUES DIAGNOSIS\n",
      "\n",
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 354 entries, H-142 to H-173\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     342 non-null    float64\n",
      " 1   ZN       340 non-null    float64\n",
      " 2   INDUS    339 non-null    float64\n",
      " 3   CHAS     340 non-null    float64\n",
      " 4   NOX      354 non-null    float64\n",
      " 5   RM       354 non-null    float64\n",
      " 6   AGE      340 non-null    float64\n",
      " 7   DIS      354 non-null    float64\n",
      " 8   RAD      354 non-null    int64  \n",
      " 9   TAX      354 non-null    int64  \n",
      " 10  PTRATIO  354 non-null    float64\n",
      " 11  B        354 non-null    float64\n",
      " 12  LSTAT    337 non-null    float64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 38.7+ KB\n",
      "None\n",
      "\n",
      "Y_train info:\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 354 entries, H-142 to H-173\n",
      "Series name: MEDV\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "354 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 5.5+ KB\n",
      "None\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:  - RAD and TAX: 0.907\n"
     ]
    }
   ],
   "source": [
    "mymodel.diagnose(sample_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an instance of `sklearn.pipeline.Pipeline` object\n",
    "# User can define their own pipeline\n",
    "data_engineer_pipeline = data_engineer(\n",
    "    outlier_cols = None,\n",
    "    missing_values_cols = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"AGE\", \"LSTAT\"],\n",
    "    impute_method = [\"median\", \"median\", \"median\", \"median\", \"median\", \"median\"],\n",
    "    cat_features = None,\n",
    "    encode_method = None,\n",
    "    # scale_cols = [\"CRIM\", \"ZN\"],\n",
    "    # scale_method = [\"standard\", \"minmax\"],\n",
    "    n_jobs = -1,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The Scaler is recommended for:\n",
      "    - LinearRegression\n",
      "    - LogisticRegression\n",
      "    - SVR\n",
      "    - SVC\n",
      "    - KNR\n",
      "    - KNC\n",
      "    - MLPRegressor\n",
      "    - MLPClassifier\n",
      "\n",
      "Best trial: 8. Best value: 0.626241: 100%|██████████| 10/10 [01:02<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "mymodel.optimize(\n",
    "    model_name = \"mlpr\",\n",
    "    data_engineer_pipeline = data_engineer_pipeline,\n",
    "    cv = 5,\n",
    "    trials = 10,\n",
    "    n_jobs = -1,\n",
    "    # cat_features = None,\n",
    "    optimize_history = True,\n",
    "    save_optimal_params = True,\n",
    "    save_optimal_model = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [354, 152]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmymodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_raw_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/mymodels/mymodels/pipeline.py:232\u001b[0m, in \u001b[0;36mMyPipeline.evaluate\u001b[0;34m(self, dummy, save_raw_data)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the model\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    dummy (bool): Whether to use a dummy estimator for comparison. Default is True.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    save_raw_data (bool): Whether to save the raw prediction data. Default is True.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m MyEvaluator()\n\u001b[0;32m--> 232\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimal_model_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_engineer_pipeline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_engineer_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Output options\u001b[39;49;00m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_format\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_dpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_raw_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_raw_data\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/mymodels/mymodels/_evaluator.py:117\u001b[0m, in \u001b[0;36mMyEvaluator.evaluate\u001b[0;34m(self, x_test, x_train, y_test, y_train, optimal_model_object, data_engineer_pipeline, dummy, results_dir, show, plot_format, plot_dpi, print_results, save_results, save_raw_data)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Dummy evaluation\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dummy_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Save all results\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output()\n",
      "File \u001b[0;32m~/workspace/mymodels/mymodels/_evaluator.py:141\u001b[0m, in \u001b[0;36mMyEvaluator._dummy_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m _dummy_predictions \u001b[38;5;241m=\u001b[39m _dummy_estimator\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_model_object):\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy_accuracy_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_accuracy_4_regression_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dummy_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dummy_predictions\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_model_object):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy_accuracy_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_accuracy_4_classification_task(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, _dummy_predictions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, _dummy_predictions\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/mymodels/mymodels/_evaluator.py:169\u001b[0m, in \u001b[0;36mMyEvaluator._get_accuracy_4_regression_task\u001b[0;34m(self, y_test, y_test_pred, y_train, y_train_pred)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_accuracy_4_regression_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_test, y_test_pred, y_train, y_train_pred):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate regression accuracy metrics for both test and training data.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Computes R², RMSE, and MAE metrics for both test and training predictions\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m        y_train_pred: Predicted training target values.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     accuracy_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m({\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_r2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(r2_score(y_test, y_test_pred)),\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(root_mean_squared_error(y_test, y_test_pred)),\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_mae\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(mean_absolute_error(y_test, y_test_pred)),\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_r2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(root_mean_squared_error(y_train, y_train_pred)),\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_mae\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(mean_absolute_error(y_train, y_train_pred))\n\u001b[1;32m    172\u001b[0m     })\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/mymodels/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mymodels/lib/python3.10/site-packages/sklearn/metrics/_regression.py:1204\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m   1198\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[1;32m   1199\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1202\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1204\u001b[0m _, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mymodels/lib/python3.10/site-packages/sklearn/metrics/_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 111\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/mymodels/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [354, 152]"
     ]
    }
   ],
   "source": [
    "mymodel.evaluate(\n",
    "    dummy = True,\n",
    "    save_raw_data = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.explain(\n",
    "    select_background_data = \"train\",\n",
    "    select_shap_data = \"test\",\n",
    "    sample_background_data_k = 50,\n",
    "    sample_shap_data_k = 50,\n",
    "    output_raw_data = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
